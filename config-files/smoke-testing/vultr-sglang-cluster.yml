# Adapted from ../nod-ai/linux-mi300-1gpu-ossci-nod-ai.yaml
# Deployment command:
# helm install arc --namespace "arc-test" --create-namespace oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller
# helm upgrade --install "arc-runner-vultr-sglang-mi300-smoketest" --namespace "arc-test" oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set -f <path-to-this-file>

controllerServiceAccount:
  name: arc-gha-rs-controller
  namespace: arc-test
template:
  spec:
    nodeSelector:
      kubernetes.io/hostname: chi-mi300x-036 # /mnt_k8s/persistant & /mnt_k8s/cache must manually be created as directories on the selected node before running
    initContainers:
      - name: init-dind-externals
        image: ghcr.io/saienduri/ghascale-rocm-dev:main
        imagePullPolicy: Always
        command:
          ["cp", "-r", "/home/runner/externals/.", "/home/runner/tmpDir/"]
        volumeMounts:
          - name: dind-externals
            mountPath: /home/runner/tmpDir
      - name: dind
        image: ghcr.io/saienduri/dind:main
        restartPolicy: Always
        command: ["sh", "-c"]
        args:
          - |
            dockerd --host=unix:///var/run/docker.sock --group=${DOCKER_GROUP_GID} &
            until docker info >/dev/null 2>&1; do sleep 5; done
            tail -f /dev/null
        env:
          - name: DOCKER_GROUP_GID
            value: "123"
          - name: IREE_TEST_FILES
            value: /shark-cache/data/iree-regression-cache
        securityContext:
          privileged: true
          #fsGroup: 1001  # This was causing issues
        volumeMounts:
          - name: work
            mountPath: /home/runner/_work
          - name: dind-sock
            mountPath: /var/run
          - name: dind-externals
            mountPath: /home/runner/externals
          - name: podinfo
            mountPath: /etc/podinfo
          - name: k8s-mount
            mountPath: /shark-dev
            readOnly: True
          - name: k8s-cache
            mountPath: /shark-cache
            readOnly: False
    containers:
      - name: runner
        image: ghcr.io/saienduri/ghascale-rocm-dev:main
        ports:
          - containerPort: 8080
        imagePullPolicy: Always
        command:
          - /bin/sh
          - -c
          - |
            devices=$(ls -la /dev/dri/ | grep renderD | awk '{print $10}')
            GHA_RENDER_DEVICES=""
            for device in $devices; do
              GHA_RENDER_DEVICES="${GHA_RENDER_DEVICES} --device /dev/dri/${device}"
            done
            echo "${GHA_RENDER_DEVICES}" > /etc/podinfo/gha-render-devices
            echo "Waiting for docker..."
            until docker info >/dev/null 2>&1; do sleep 5; done
            /home/runner/run.sh
        resources:
          requests:
            cpu: 25000m
            memory: 75000Mi
            amd.com/gpu: 1
          limits:
            amd.com/gpu: 1
        env:
          - name: DOCKER_HOST
            value: unix:///var/run/docker.sock
          - name: IREE_TEST_FILES
            value: /shark-cache/data/iree-regression-cache
        volumeMounts:
          - name: work
            mountPath: /home/runner/_work
          - name: dind-sock
            mountPath: /var/run
          - name: dind-externals
            mountPath: /home/runner/externals
          - name: podinfo
            mountPath: /etc/podinfo
          - name: k8s-mount
            mountPath: /shark-dev
            readOnly: True
          - name: k8s-cache
            mountPath: /shark-cache
            readOnly: False

    volumes:
      - name: work
        emptyDir: {}
      - name: dind-sock
        emptyDir: {}
      - name: dind-externals
        emptyDir: {}
      - name: podinfo
        emptyDir: {}
      - name: k8s-mount
        hostPath:
          path: /mnt_k8s/persistant
          type: Directory
      - name: k8s-cache
        hostPath:
          path: /mnt_k8s/cache
          type: Directory

githubConfigUrl: https://github.com/singhish/arc-testing-aws-stg
githubConfigSecret:
  github_token: # my PAT
